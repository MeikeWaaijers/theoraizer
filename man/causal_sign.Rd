% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/causal_sign.R
\name{causal_sign}
\alias{causal_sign}
\title{Identify the Sign of Causal Relationships}
\usage{
causal_sign(topic,
            prob_df,
            causal_threshold = 50,
            LLM_model = "gpt-4o",
            max_tokens = 2000,
            update_key = FALSE)
}
\arguments{
\item{topic}{A character vector specifying the topic for which a theory should be developed. If it is not feasible to identify a particular topic, the argument can be set to NULL.}

\item{prob_df}{Two different probability dataframes can be inputted:
\itemize{
  \item A dataframe with 3 columns and on every row a unique variable pair and the probability of the presence of a causal relationship between these variables (The \code{relation_df} output from the \code{\link{causal_relation}} function).
  \item A dataframe with 5 columns and on every row a unique variable pair, the probability of the presence of a causal relationship between these variables, and the cause variable probability for each variable in the pair (The \code{direction_df} output from the \code{\link{causal_direction}} function).
}}

\item{causal_threshold}{A number (defaults to \code{50}) that indicates the minimum probability required for a causal relationship to be included in the plot.}

\item{LLM_model}{The LLM model that should be used to generate output: \code{"gpt-4o"} (default), \code{"gpt-4"}, \code{"gpt-4-turbo"} \code{"gpt-3.5-turbo"}, \code{"llama-3"} (specifically points to Llama-3-70B-Chat-hf, accessed via Hugging Face), or \code{"mixtral"} (specifically points to Mixtral-8x7B-Instruct-v0.1, accessed via Together.ai).}

\item{max_tokens}{The maximum number of tokens the LLM should generate. Be careful when adjusting this argument. Reducing the maximum token limit will reduce the cost but may result in incomplete answers. Conversely, increasing the token limit can be advantageous for obtaining more detailed responses. The maximum number of tokens depends on the model (\code{6000} for \code{"gpt-4o"}, \code{"gpt-4"}, and \code{"gpt-4-turbo"}, \code{3000} for \code{"gpt-3.5-turbo"}, and \code{2000} for \code{"mixtral"}).}

\item{update_key}{If \code{update_key = TRUE}, the function will prompt the user for a new API key and update the saved key. If \code{update_key = FALSE} (default), the function will use the existing API key if available.}
}
\value{
The output is an extended version of the inputted probability dataframe. The output will therefore vary depending on whether the original input was a relation or a direction dataframe.

\itemize{
 If a relation dataframe is inputted:
  \itemize{
    \item \code{raw_LLM}: A dataframe containing the unprocessed LLM output along with some other LLM information, including:
      \itemize{
        \item \code{relationship}: Which variable pair.
        \item \code{iteration}: Iteration number.
        \item \code{LLM_model}: LLM model used.
        \item \code{prompt}: Prompt used.
        \item \code{system_prompt}: System prompt used.
        \item \code{content}: Unprocessed LLM output.
        \item \code{finish_reason}: Reason the LLM stopped generating output.
        \item \code{prompt_tokens}: Number of tokens used for the LLM prompt.
        \item \code{answer_tokens}: Number of tokens used for the LLM answer.
        \item \code{total_tokens}: Total number of tokens used.
        \item \code{error}: Error message, if any occurred.
    }
  } \cr
  \itemize{
    \item \code{sign_df}: A dataframe with five columns:
      \itemize{
        \item \code{var1}: Variable 1 of a unique variable pair.
        \item \code{var2}: Variable 2 of a unique variable pair.
        \item \code{prob_causal}: Probability of the presence of a causal relationship between var1 and var2.
        \item \code{prob_pos}: Probability of a positive relationship.
        \item \code{prob_neg}: Probability of a negative relationship.
      }
  }
} \cr
\itemize{
 If a direction dataframe is inputted:
  \itemize{
    \item \code{raw_LLM}: A dataframe containing the unprocessed LLM output along with some other LLM information, including:
      \itemize{
        \item \code{var}: Which variable is put in the prompt as cause variable.
        \item \code{relationship}: Which variable pair.
        \item \code{iteration}: Iteration number.
        \item \code{LLM_model}: LLM model used.
        \item \code{prompt}: Prompt used.
        \item \code{system_prompt}: System prompt used.
        \item \code{content}: Unprocessed LLM output.
        \item \code{finish_reason}: Reason the LLM stopped generating output.
        \item \code{prompt_tokens}: Number of tokens used for the LLM prompt.
        \item \code{answer_tokens}: Number of tokens used for the LLM answer.
        \item \code{total_tokens}: Total number of tokens used.
        \item \code{error}: Error message, if any occurred.
    }
  } \cr
  \itemize{
    \item \code{sign_df}: A dataframe with nine columns:
      \itemize{
        \item \code{var1}: Variable 1 of a unique variable pair.
        \item \code{var2}: Variable 2 of a unique variable pair.
        \item \code{prob_causal}: Probability of the presence of a causal relationship between var1 and var2.
        \item \code{prob_var1_cause}: Probability of var1 being a cause variable.
        \item \code{prob_var1_pos}: Probability of a positive relationship where variable 1 is the cause.
        \item \code{prob_var1_neg}: Probability of a negative relationship where variable 1 is the cause.
        \item \code{prob_var2_cause}: Probability of var2 being a cause variable.
        \item \code{prob_var2_pos}: Probability of a positive relationship where variable 2 is the cause.
        \item \code{prob_var2_neg}: Probability of a negative relationship where variable 2 is the cause.
    }
  }
}
}
\description{
In \code{causal_sign()} a Large Language Model (LLM) is asked to determine whether a causal relationship is positive or negative. This is achieved by asking the LLM how an increase or decrease in one variable affects the other variable.
}
\details{
To create a fully fledged theory from scratch, the functions in this R-packaged should be used in the following order:

\code{\link{var_list}} --> \code{\link{causal_relation}} --> \code{\link{causal_direction}} --> \code{\link{causal_sign}} --> \code{\link{cld_plot}}
}
\note{
The function and its output should be approached with caution. Depending on the specific LLM used, there may be financial implications. Furthermore, we wish to emphasise that the answers generated by an LLM should not be taken as absolute truth.
}
\examples{
\dontrun{
## Example input (topic = "addiction")
# Relation probability dataframe input
data("rel")
rel$relation_df

# Direction probability dataframe input
data("dir")
dir$direction_df

#---------------------------------------------------------------------------
## Create sign dataframe for a relation probability dataframe
# For a readily available, pre-made output example see: data("rel_sign")
rel_sign <- causal_sign(topic = "addiction",
                        prob_df = rel$relation_df)

# Check output
rel_sign$sign_df

#---------------------------------------------------------------------------
## Create sign dataframe for a direction probability dataframe
# For a readily available, pre-made output example see: data("dir_sign")
dir_sign <- causal_sign(topic = "addiction",
                        prob_df = dir$direction_df)

# Check output
dir_sign$sign_df
}
}
\references{
\url{https://platform.openai.com}
}
\seealso{
\code{\link{cld}},
\code{\link{var_list}},
\code{\link{causal_relation}},
\code{\link{causal_direction}},
\code{\link{cld_plot}},
}
\author{
Meike Waaijers
}
