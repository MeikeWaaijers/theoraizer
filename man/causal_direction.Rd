% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/causal_direction.R
\name{causal_direction}
\alias{causal_direction}
\title{Identify the Direction of Causal Relationships}
\usage{
causal_direction(topic,
                 relation_df,
                 causal_threshold = 50,
                 LLM_model = "gpt-4o",
                 max_tokens = 2000,
                 update_key = FALSE)
}
\arguments{
\item{topic}{A character vector specifying the topic for which a theory should be developed. If it is not feasible to identify a particular topic, the argument can be set to NULL.}

\item{relation_df}{A dataframe with a unique pair of variables on each row and the probability of the existence of a causal relationship between these variables. (The \code{relation_df} output of the \code{\link{causal_relation}} function).}

\item{causal_threshold}{A number (defaults to \code{50}) that indicates the minimum probability required for a causal relationship to be included.}

\item{LLM_model}{The LLM model that should be used to generate output: \code{"gpt-4o"} (default), \code{"gpt-4"}, \code{"gpt-4-turbo"} \code{"gpt-3.5-turbo"}, or \code{"mixtral"}.}

\item{max_tokens}{The maximum number of tokens the LLM should generate. Be careful when adjusting this argument. Reducing the maximum token limit will reduce the cost but may result in incomplete answers. Conversely, increasing the token limit can be advantageous for obtaining more detailed responses. The maximum number of tokens depends on the model (\code{6000} for \code{"gpt-4o"}, \code{"gpt-4"}, and \code{"gpt-4-turbo"}, \code{3000} for \code{"gpt-3.5-turbo"}, and \code{2000} for \code{"mixtral"}).}

\item{update_key}{If \code{update_key = TRUE}, the function will prompt the user for a new API key and update the saved key. If \code{update_key = FALSE} (default), the function will use the existing API key if available.}
}
\value{
\itemize{
  \item \code{raw_LLM}: A dataframe containing the unprocessed LLM output along with some other LLM information, including:
    \itemize{
      \item \code{var}: Which variable is put in the prompt as cause variable.
      \item \code{relationship}: Which variable pair.
      \item \code{iteration}: Iteration number.
      \item \code{LLM_model}: LLM model used.
      \item \code{prompt}: The prompt asked to the LLM.
      \item \code{system_prompt}: System prompt used.
      \item \code{content}: Unprocessed LLM output.
      \item \code{finish_reason}: Reason the LLM stopped generating output.
      \item \code{prompt_tokens}: Number of tokens used for the LLM prompt.
      \item \code{answer_tokens}: Number of tokens used for the LLM answer.
      \item \code{total_tokens}: Total number of tokens used.
      \item \code{error}: Error message, if any occurred.
    }
} \cr
\itemize{
  \item \code{direction_df}: A dataframe with five columns:
    \itemize{
      \item \code{var1}: Variable 1 of a unique variable pair.
      \item \code{var2}: Variable 2 of a unique variable pair.
      \item \code{prob_causal}: Probability of the presence of a causal relationship between var1 and var2.
      \item \code{prob_var1_cause}: Probability of var1 being a cause variable.
      \item \code{prob_var2_cause}: Probability of var2 being a cause variable.
    }
}
}
\description{
In \code{causal_direction()} a Large Language Model (LLM) is asked to indicate the causal direction for each pair of variables previously classified as "causal". This is done by asking the LLM to indicate whether a change in one variable will directly cause a change in the other variable.
}
\details{
To create a fully fledged theory from scratch, the functions in this R-packaged should be used in the following order:

\code{\link{var_list}} --> \code{\link{causal_relation}} --> \code{\link{causal_direction}} --> \code{\link{causal_sign}} --> \code{\link{cld_plot}}
}
\note{
The function and its output should be approached with caution. Depending on the specific LLM used, there may be financial implications. Furthermore, we wish to emphasise that the answers generated by an LLM should not be taken as absolute truth.
}
\examples{
\dontrun{
## Example input (topic = "addiction")
data("rel")
rel$relation_df

#---------------------------------------------------------------------------
## Default
# For a readily available, pre-made output example see: data("dir")
dir <- causal_direction(topic = "addiction",
                        relation_df = rel$relation_df)

# Check output
dir$direction_df
}
}
\references{
\url{https://platform.openai.com}
}
\seealso{
\code{\link{cld}},
\code{\link{var_list}},
\code{\link{causal_relation}},
\code{\link{causal_sign}},
\code{\link{cld_plot}},
}
\author{
Meike Waaijers
}
