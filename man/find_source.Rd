% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/find_source.R
\name{find_source}
\alias{find_source}
\title{Find Scientific Sources for Causal Relationships}
\usage{
find_source(topic,
            edge_list = NULL,
            causal_threshold = 50,
            scientific = TRUE,
            LLM_model = "gpt-4.1",
            max_tokens = 2000,
            update_key = FALSE)
}
\arguments{
\item{topic}{A character vector specifying the topic for which a theory should be developed. If it is not feasible to identify a particular topic, the argument can be set to NULL.}

\item{edge_list}{A data frame representing a causal edge list, with one row per putative causal relationship. Must contain at least three columns: \code{from}, a character column naming the cause variable; \code{to}, a character column naming the dependent variable; and \code{weight}, a numeric column giving the probability of a causal relationship. Optionally, a fourth column \code{sign} can be included with values \code{"Positive"}, \code{"Negative"}, or \code{"Uncertain"} to indicate the sign of the relationship.}

\item{causal_threshold}{A number (defaults to \code{50}) used to determine how to interpret the causal relationship. If an edge's weight is greater than this threshold, the model is asked to find a source that supports a causal relationship. If the weight is equal to or below the threshold, the model is asked to find a source indicating no causal relationship.}

\item{scientific}{If \code{scientific = TRUE } (default), the LLM is asked to find a scientific publication as a source. If \code{FALSE}, any credible source is allowed.}

\item{LLM_model}{The LLM model that should be used to generate output. As of now, only \code{"gpt-4.1"} is available for this function. Other models may be added in future updates.}

\item{max_tokens}{The maximum number of tokens the LLM should generate. Be careful when adjusting this argument. Reducing the maximum token limit will reduce the cost but may result in incomplete answers. Conversely, increasing the token limit can be advantageous for obtaining more detailed responses. The maximum number of tokens depends on the model. As of now, only \code{"gpt-4.1"} is supported for this function, with a maximum token limit of \code{6000}.}

\item{update_key}{If \code{update_key = TRUE}, the function will prompt the user for a new API key and update the saved key. If \code{update_key = FALSE} (default), the function will use the existing API key if available.}
}
\value{
\itemize{
  \item \code{raw_LLM}: A dataframe containing the unprocessed LLM output along with some other LLM information, including:
    \itemize{
      \item \code{relationship}: Which variable pair.
      \item \code{LLM_model}: LLM model used.
      \item \code{prompt}: The prompt asked to the LLM.
      \item \code{content}: Unprocessed LLM output.
      \item \code{finish_reason}: Reason the LLM stopped generating output.
      \item \code{prompt_tokens}: Number of tokens used for the LLM prompt.
      \item \code{answer_tokens}: Number of tokens used for the LLM answer.
      \item \code{total_tokens}: Total number of tokens used.
      \item \code{error}: Error message, if any occurred.
    }
} \cr
\itemize{
  \item \code{edge_list_with_sources}: The input \code{edge_list} with all its original columns retained, plus two new ones:
    \itemize{
    \item \code{from}: The cause variable.
    \item \code{to}: The dependent variable.
    \item \code{weight}: The weight associated with the causal relationship.
    \item \code{sign}: (Optional) The sign of the causal relationship (can be either "Positive", "Negative", or "Uncertain").
    \item \code{explanation}: A short summary of the sources identified by the model, typically including the key findings and how they relate to the causal relationship. May also note when no direct publication was found.
    \item \code{sources}: One or more citation links returned by the model, stored as a semicolon separated string.
    }
}
}
\description{
\code{find_source()} iterates over an edge list of putative causal relationships and asks a Large Language Model (LLM) to find and summarize relevant sources for each relationship.
}
\details{
To create a theory from scratch, the functions in this R-package should be used in the following order:

\code{\link{var_list}} --> \code{\link{causal_relation}} --> \code{\link{causal_direction}} --> \code{\link{causal_sign}} --> \code{\link{cld_plot}} --> \code{\link{find_source}}
}
\note{
The function and its output should be approached with caution. Depending on the specific LLM used, there may be financial implications. Furthermore, we wish to emphasise that the answers generated by an LLM should not be taken as absolute truth.
}
\examples{
\dontrun{
## Example input (topic = "addiction")
data("edge_lists")

# Use the direction + sign edge list (columns: from, to, weight, sign)
input <- edge_lists$dir_sign_edge_list[, 1:4]

#---------------------------------------------------------------------------
## Default
# For a readily available, pre-made output example see: data("sources")
sources <- find_source(topic = "addiction",
                       edge_list = input)

# Check output
sources$edge_list_with_sources
}

}
\references{
\url{https://platform.openai.com}
}
\seealso{
\code{\link{cld}},
\code{\link{var_list}},
\code{\link{causal_relation}},
\code{\link{causal_direction}},
\code{\link{causal_sign}},
\code{\link{cld_plot}}
}
\author{
Meike Waaijers
}
