# Program Name: theoraizer
# Description: In the causal_direction function a Large Language Model (LLM) is asked to indicate the causal direction for pairs of variables classified as "causal".
# Copyright (C) <2024> <Meike Waaijers>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.


#### theoraizer
### Causal direction function

## Function manual

#' Identify the Direction of Causal Relationships
#'
#' @description
#' In \code{causal_direction()} a Large Language Model (LLM) is asked to indicate the causal direction for each pair of variables previously classified as "causal". This is done by asking the LLM to indicate whether a change in one variable will directly cause a change in the other variable.
#'
#' @usage
#' causal_direction(context,
#'                  relation_df,
#'                  causal_threshold = 50,
#'                  LLM_model = "gpt-4o",
#'                  max_tokens = 2000,
#'                  update_key = FALSE)
#' @details
#' To create a fully fledged theory from scratch, the functions in this R-packaged should be used in the following order:
#'
#' \code{\link{var_list}} --> \code{\link{causal_relation}} --> \code{\link{causal_direction}} --> \code{\link{causal_sign}} --> \code{\link{cld_plot}}
#'
#' @param context A character vector specifying the context for which a theory should be developed. If it is not feasible to identify a particular context, the argument can be set to NULL.
#' @param relation_df A dataframe with a unique pair of variables on each row and the probability of the existence of a causal relationship between these variables. (The \code{relation_df} output of the \code{\link{causal_relation}} function).
#' @param causal_threshold A number (defaults to \code{50}) that indicates the minimum probability required for a causal relationship to be included.
#' @inheritParams var_list
#'
#' @returns
#' \itemize{
#'   \item \code{raw_LLM}: A dataframe containing the unprocessed LLM output along with some other LLM information, including:
#'     \itemize{
#'       \item \code{var}: Which variable is put in the prompt as cause variable.
#'       \item \code{relationship}: Which variable pair.
#'       \item \code{iteration}: Iteration number.
#'       \item \code{LLM_model}: LLM model used.
#'       \item \code{prompt}: The prompt asked to the LLM.
#'       \item \code{system_prompt}: System prompt used.
#'       \item \code{content}: Unprocessed LLM output.
#'       \item \code{finish_reason}: Reason the LLM stopped generating output.
#'       \item \code{prompt_tokens}: Number of tokens used for the LLM prompt.
#'       \item \code{answer_tokens}: Number of tokens used for the LLM answer.
#'       \item \code{total_tokens}: Total number of tokens used.
#'       \item \code{error}: Error message, if any occurred.
#'     }
#' } \cr
#' \itemize{
#'   \item \code{direction_df}: A dataframe with five columns:
#'     \itemize{
#'       \item \code{var1}: Variable 1 of a unique variable pair.
#'       \item \code{var2}: Variable 2 of a unique variable pair.
#'       \item \code{prob_causal}: Probability of the presence of a causal relationship between var1 and var2.
#'       \item \code{prob_var1_cause}: Probability of var1 being a cause variable.
#'       \item \code{prob_var2_cause}: Probability of var2 being a cause variable.
#'     }
#' }
#'
#' @references \url{https://platform.openai.com}
#'
#' @author Meike Waaijers
#'
#' @note The function and its output should be approached with caution. Depending on the specific LLM used, there may be financial implications. Furthermore, we wish to emphasise that the answers generated by an LLM should not be taken as absolute truth.
#'
#' @seealso
#' \code{\link{cld}},
#' \code{\link{var_list}},
#' \code{\link{causal_relation}},
#' \code{\link{causal_sign}},
#' \code{\link{cld_plot}},
#'
#' @examples
#' \dontrun{
#' ## Example input (context = "addiction")
#' data("rel")
#' rel$relation_df
#'
#' #---------------------------------------------------------------------------
#' ## Default
#' # For a readily available, pre-made output example see: data("dir")
#' dir <- causal_direction(context = "addiction",
#'                         relation_df = rel$relation_df)
#'
#' # Check output
#' dir$direction_df
#' }
#' @import httr
#' @import utils
#' @import keyring
#' @export


## causal_direction function
causal_direction <- function(context,
                             relation_df,
                             causal_threshold = 50,
                             LLM_model = "gpt-4o",
                             max_tokens = 2000,
                             update_key = FALSE) {

  #validate input
  stopifnot("'context' should be a character string or NULL." = is.character(context) | is.null(context))
  stopifnot("'causal_threshold' should be a number between 0 and 100, and cannot have more than two decimal points." =
              is.numeric(causal_threshold) && causal_threshold >= 0 && causal_threshold <= 100 && round(causal_threshold, 2) == causal_threshold)
  stopifnot("'relation_df' should be a dataframe." = is.data.frame(relation_df))
  stopifnot("'relation_df' should have three columns named 'var1', 'var2' and 'prob_causal'." =
              ncol(relation_df) == 3 && all(paste(c("var1", "var2", "prob_causal"), collapse = ", ") == paste(names(relation_df), collapse = ", ")))
  stopifnot("All entries in 'relation_df$var1' and 'relation_df$var2' should be character strings." =
              all(sapply(relation_df$var1, is.character)) && all(sapply(relation_df$var2, is.character)))
  stopifnot("All entries in 'relation_df$prob_causal' should be numeric and between 0 and 100." =
              all(sapply(relation_df$prob_causal, function(x) is.numeric(x) && x >= 0 && x <= 100)))
  stopifnot("At least one variable pair should be classified as 'causal'." = sum(relation_df$prob_causal) > 0)
  stopifnot("'LLM_model' should be 'gpt-4o', 'gpt-4', 'gpt-4-turbo', 'gpt-3.5-turbo', 'mixtral', or 'llama-3'." =
              LLM_model %in% c("mixtral", "gpt-4o", "gpt-4", "gpt-4-turbo", "gpt-3.5-turbo", "llama-3"))
  stopifnot("For 'gpt-4o', 'max_tokens' should be a whole number above 0, and not higher than 6000." =
              !(LLM_model == "gpt-4o") || (is.numeric(max_tokens) && max_tokens == floor(max_tokens) && max_tokens >= 0 && max_tokens <= 6000))
  stopifnot("For 'gpt-4', 'max_tokens' should be a whole number above 0, and not higher than 6000." =
              !(LLM_model == "gpt-4") || (is.numeric(max_tokens) && max_tokens == floor(max_tokens) && max_tokens >= 0 && max_tokens <= 6000))
  stopifnot("For 'gpt-4-turbo', 'max_tokens' should be a whole number above 0, and not higher than 6000." =
              !(LLM_model == "gpt-4-turbo") || (is.numeric(max_tokens) && max_tokens == floor(max_tokens) && max_tokens >= 0 && max_tokens <= 6000))
  stopifnot("For 'gpt-3.5-turbo', 'max_tokens' should be a whole number above 0, and not higher than 3000." =
              !(LLM_model == "gpt-3.5-turbo") || (is.numeric(max_tokens) && max_tokens == floor(max_tokens) && max_tokens >= 0 && max_tokens <= 3000))
  stopifnot("For 'mixtral', 'max_tokens' should be a whole number above 0, and not higher than 2000." =
              !(LLM_model == "mixtral") || (is.numeric(max_tokens) && max_tokens == floor(max_tokens) && max_tokens >= 0 && max_tokens <= 2000))
  stopifnot("For 'llama-3', 'max_tokens' should be a whole number above 0, and not higher than 6000." =
              !(LLM_model == "llama-3") || (is.numeric(max_tokens) && max_tokens == floor(max_tokens) && max_tokens >= 0 && max_tokens <= 6000))
  stopifnot("'update_key' should be a logical value." = is.logical(update_key))

  ## Load and prepare prompt data
  prompt_file_path <- system.file("extdata", "prompts.csv", package = "theoraizer")
  prompts_data <- utils::read.csv(prompt_file_path, sep = ";")


  # replace '\\n' with '\n' in all text columns
  for (i in 1:length(prompts_data$Prompt)) {
    # Check if the prompt column is a character type
    if (is.character(prompts_data$Prompt[[i]])) {
      # Replace '\\n' with '\n' in the column
      prompts_data$Prompt[[i]] <- gsub("\\n", "\n", prompts_data$Prompt[[i]], fixed = TRUE)
    }

    # Check if the sys prompt column is a character type
    if (is.character(prompts_data$Sys.Prompt[[i]])) {
      # Replace '\\n' with '\n' in the column
      prompts_data$Sys.Prompt[[i]] <- gsub("\\n", "\n", prompts_data$Sys.Prompt[[i]], fixed = TRUE)
    }
  }

  dir_prompts <- prompts_data[prompts_data$Function == "directions", ]


  ## Create objects for tryCatch output
  # So somethings gets outputted even though an error occurs later on in the function
  raw_cause_var1 <- NULL
  raw_cause_var2 <- NULL
  raw_LLM_var1 <- NULL
  raw_LLM_var2 <- NULL
  raw_LLM <- NULL
  cause_logprobs_var1 <- NULL
  cause_logprobs_var2 <- NULL
  logprobs_LLM_var1 <- NULL
  logprobs_LLM_var2 <- NULL
  logprobs_LLM <- NULL
  direction_df <- NULL


  # get row_index of all variable pairs that were indicated to be causal at least once
  row_index <- unique(which(relation_df[3] > causal_threshold, arr.ind = TRUE)[, 1])

  # get names of the variables
  var_1 <- relation_df$var1
  var_2 <- relation_df$var2

  ## LLM
  n_causal_rela <- length(row_index) # number of causal relationships
  pair <- 1

  for (i in row_index) {
    print(paste("Variable pair:  ", pair,  "/", n_causal_rela))

    # Initialize the prompt database
    var1_prompt_database <- list()
    var2_prompt_database <- list()
    sys_prompt_database <- list()

    for (g in 1:2) {

      if (length(var1_prompt_database) == 0) {
        if (is.null(context)) {
          # Create prompts for var 1
          var1_prompt1 <- gsub("\\((var_1\\[i\\])\\)", var_1[i],
                               gsub("\\((var_2\\[i\\])\\)", var_2[i],
                                    dir_prompts$Prompt[1]))

          var1_prompt2 <- gsub("\\((var_1\\[i\\])\\)", var_1[i],
                               gsub("\\((var_2\\[i\\])\\)", var_2[i],
                                    dir_prompts$Prompt[2]))

        } else {
          # Create prompts for var 1
          var1_prompt1 <- gsub("\\((context)\\)", context,
                               gsub("\\((var_1\\[i\\])\\)", var_1[i],
                                    gsub("\\((var_2\\[i\\])\\)", var_2[i],
                                         dir_prompts$Prompt[3])))

          var1_prompt2 <- gsub("\\((context)\\)", context,
                               gsub("\\((var_1\\[i\\])\\)", var_1[i],
                                    gsub("\\((var_2\\[i\\])\\)", var_2[i],
                                         dir_prompts$Prompt[4])))

        }

        # Put all prompts in a database
        var1_prompt_database <- list(var1_prompt1, var1_prompt2)

      }

      if (length(var2_prompt_database) == 0) {
        if (is.null(context)) {
          # Create prompts for var 2
          var2_prompt1 <- gsub("\\((var_2\\[i\\])\\)", var_2[i],
                               gsub("\\((var_1\\[i\\])\\)", var_1[i],
                                    dir_prompts$Prompt[5]))

          var2_prompt2 <- gsub("\\((var_2\\[i\\])\\)", var_2[i],
                               gsub("\\((var_1\\[i\\])\\)", var_1[i],
                                    dir_prompts$Prompt[6]))

        } else {
          # Create prompts for var 2
          var2_prompt1 <- gsub("\\((context)\\)", context,
                               gsub("\\((var_2\\[i\\])\\)", var_2[i],
                                    gsub("\\((var_1\\[i\\])\\)", var_1[i],
                                         dir_prompts$Prompt[7])))

          var2_prompt2 <- gsub("\\((context)\\)", context,
                               gsub("\\((var_2\\[i\\])\\)", var_2[i],
                                    gsub("\\((var_1\\[i\\])\\)", var_1[i],
                                         dir_prompts$Prompt[8])))

        }
        # Put all prompts in a database
        var2_prompt_database <- list(var2_prompt1, var2_prompt2)

      }

      var1_prompt <- var1_prompt_database[[g]]
      var2_prompt <- var2_prompt_database[[g]]

      if (length(sys_prompt_database) == 0) {
        if (is.null(context)){
          # Create system prompts
          system_prompt1 <- dir_prompts$Sys.Prompt[1]
          system_prompt2 <- dir_prompts$Sys.Prompt[2]

        } else {
          # Create system prompts
          system_prompt1 <- dir_prompts$Sys.Prompt[3]
          system_prompt2 <- dir_prompts$Sys.Prompt[4]
        }

        # Put all prompts in a database
        sys_prompt_database <- list(system_prompt1, system_prompt2)

      }

      system_prompt <- sys_prompt_database[[g]]

      ## LLM
      # Var 1
      var1_cause <- LLM(prompt = var1_prompt,
                        LLM_model = LLM_model,
                        max_tokens = ifelse(LLM_model == "mixtral", 4, max_tokens),
                        temperature = 0, # = how creative LLM can be (0 = not creative at all so the same answer will be given if you run the exact same prompt again.)
                        logprobs = TRUE,
                        raw_output = TRUE,
                        system_prompt = system_prompt,
                        update_key = update_key)

      update_key <- FALSE # make sure api key is only updated once
      raw_cause_var1[g] <- list(c(prompt = var1_prompt, system_prompt = system_prompt, var1_cause$raw_content))
      cause_logprobs_var1[g] <- list(var1_cause$top5_tokens)


      # Var 2
      var2_cause <- LLM(prompt = var2_prompt,
                        LLM_model = LLM_model,
                        max_tokens = ifelse(LLM_model == "mixtral", 4, max_tokens),
                        temperature = 0, # = how creative LLM can be (0 = not creative at all so the same answer will be given if you run the exact same prompt again.)
                        logprobs = TRUE,
                        raw_output = TRUE,
                        system_prompt = system_prompt,
                        update_key = update_key)

      update_key <- FALSE # make sure api key is only updated once
      raw_cause_var2[g] <- list(c(prompt = var2_prompt, system_prompt = system_prompt, var2_cause$raw_content))
      cause_logprobs_var2[g] <- list(var2_cause$top5_tokens)

    }

    raw_LLM_var1[[i]] <- raw_cause_var1
    logprobs_LLM_var1[[i]] <- cause_logprobs_var1

    raw_LLM_var2[[i]] <- raw_cause_var2
    logprobs_LLM_var2[[i]] <- cause_logprobs_var2

    pair <- pair + 1

  }


  #tryCatch in case processing steps fail the raw output will still be outputted
  tryCatch({

    ## Var 1
    if (LLM_model == "mixtral" | LLM_model == "llama-3"){
      last_token_f_var1 <- NULL
      for (i in row_index) {
        last_token_t <- NULL
        for (j in 1:length(logprobs_LLM_var1[[i]])){
          last_token_t[[j]] <- logprobs_LLM_var1[[i]][[j]][[1]]
          last_token_t[[j]]$top5_tokens <- trimws(tolower(last_token_t[[j]]$top5_tokens))
        }
        last_token_f_var1[[i]] <- last_token_t
      }

    } else {

      last_token_f_var1 <- NULL
      for (i in row_index) {
        last_token_t <- NULL
        for (j in 1:length(logprobs_LLM_var1[[i]])){
          last_token_t[[j]] <- logprobs_LLM_var1[[i]][[j]][[length(logprobs_LLM_var1[[i]][[j]])]]
          last_token_t[[j]]$top5_tokens <- trimws(tolower(last_token_t[[j]]$top5_tokens))
        }
        last_token_f_var1[[i]] <- last_token_t
      }
    }

    all_prob_var1 <- list()
    valid_tokens <- c("yes", "no")

    for (l in row_index) {
      probs <- list()
      for (g in 1:length(last_token_f_var1[[l]])){
        class <- NULL
        prob <- NULL
        k <- 1
        # Process each item in last_token
        for (m in 1:nrow(last_token_f_var1[[l]][[g]])) {
          if (trimws(tolower(last_token_f_var1[[l]][[g]]$top5_tokens[m])) %in% valid_tokens) {
            # Filter and extract required values
            if (trimws(tolower(gsub("[\n]", "", last_token_f_var1[[l]][[g]]$top5_tokens[m]))) == "yes"){
              class[k] <- var_1[l]
              prob[k] <- last_token_f_var1[[l]][[g]]$probability[m]
            } else if (trimws(tolower(gsub("[\n]", "", last_token_f_var1[[l]][[g]]$top5_tokens[m]))) == "no"){
              class[k] <- "-"
              prob[k] <- "-"
            }
            k <- k + 1
          }
        }
        # Filter positive probabilities
        positive_probs <- prob > 0 | prob == "-"
        probs[[g]] <- data.frame(Class = class[positive_probs], Probability = prob[positive_probs])
      }
      all_prob_var1[[l]] <- probs
    }

    ## Var 2
    if (LLM_model == "mixtral" | LLM_model == "llama-3"){
      last_token_f_var2 <- NULL
      for (i in row_index) {
        last_token_t <- NULL
        for (j in 1:length(logprobs_LLM_var2[[i]])){
          last_token_t[[j]] <- logprobs_LLM_var2[[i]][[j]][[1]]
          last_token_t[[j]]$top5_tokens <- trimws(tolower(last_token_t[[j]]$top5_tokens))
        }
        last_token_f_var2[[i]] <- last_token_t
      }

    } else {
      last_token_f_var2 <- NULL
      for (i in row_index) {
        last_token_t <- NULL
        for (j in 1:length(logprobs_LLM_var2[[i]])){
          last_token_t[[j]] <- logprobs_LLM_var2[[i]][[j]][[length(logprobs_LLM_var2[[i]][[j]])]]
          last_token_t[[j]]$top5_tokens <- trimws(tolower(last_token_t[[j]]$top5_tokens))
        }
        last_token_f_var2[[i]] <- last_token_t
      }
    }

    all_prob_var2 <- list()
    valid_tokens <- c("yes", "no")

    for (l in row_index) {
      probs <- list()
      for (g in 1:length(last_token_f_var2[[l]])){
        class <- NULL
        prob <- NULL
        k <- 1
        # Process each item in last_token
        for (m in 1:nrow(last_token_f_var2[[l]][[g]])) {
          if (trimws(tolower(last_token_f_var2[[l]][[g]]$top5_tokens[m])) %in% valid_tokens) {
            # Filter and extract required values
            if (trimws(tolower(gsub("[\n]", "", last_token_f_var2[[l]][[g]]$top5_tokens[m]))) == "yes"){
              class[k] <- var_2[l]
              prob[k] <- last_token_f_var2[[l]][[g]]$probability[m]
            } else if (trimws(tolower(gsub("[\n]", "", last_token_f_var2[[l]][[g]]$top5_tokens[m]))) == "no"){
              class[k] <- "-"
              prob[k] <- "-"
            }
            k <- k + 1
          }
        }
        # Filter positive probabilities
        positive_probs <- prob > 0 | prob == "-"
        probs[[g]] <- data.frame(Class = class[positive_probs], Probability = prob[positive_probs])
      }
      all_prob_var2[[l]] <- probs
    }


    # get Probability per variable per causal relationship
    var1_prob_f <- 0
    var2_prob_f <- 0
    for (w in row_index) {
      var1_prob_t <- 0
      var2_prob_t <- 0
      for (z in 1:2) {
        for (x in 1:nrow(all_prob_var1[[w]][[z]])) {
          if (all_prob_var1[[w]][[z]]$Class[[x]] == var_1[w]) {
            var1_prob_t <- var1_prob_t + as.numeric(all_prob_var1[[w]][[z]]$Probability[[x]])
          }
        }
        for (j in 1:nrow(all_prob_var2[[w]][[z]])) {
          if (all_prob_var2[[w]][[z]]$Class[[j]] == var_2[w]) {
            var2_prob_t <- var2_prob_t + as.numeric(all_prob_var2[[w]][[z]]$Probability[[j]])
          }
        }
      }
      var1_prob_f[w] <- ifelse((var1_prob_t / 2) > 100, round((var1_prob_t / 2)), round((var1_prob_t / 2), 2))
      var2_prob_f[w] <- ifelse((var2_prob_t / 2) > 100, round((var2_prob_t / 2)), round((var2_prob_t / 2), 2))
    }

    #replace absent relations with 0
    var1_prob_f[is.na(var1_prob_f)] <- 0
    var2_prob_f[is.na(var2_prob_f)] <- 0

    # create direction prob df
    direction_df <- data.frame(var1 = relation_df$var1,
                               var2 = relation_df$var2,
                               prob_causal = relation_df$prob_causal,
                               prob_var1_cause = 0,
                               prob_var2_cause = 0)

    #make sure dataframes are of equal length and add probabilities to df
    if(length(var1_prob_f) < nrow(direction_df)) {
      var1_prob_f[(length(var1_prob_f) + 1) : nrow(direction_df)] <- 0
    }
    if(length(var2_prob_f) < nrow(direction_df)) {
      var2_prob_f[(length(var2_prob_f) + 1) : nrow(direction_df)] <- 0
    }
    # add direction probabilities
    direction_df$prob_var1_cause <- var1_prob_f
    direction_df$prob_var2_cause <- var2_prob_f


  }, error = function(e) {
    cat(paste0("Warning: Unable to process LLM output -> ", e$message, "."),
        "Only part of the output is returned.", sep = "\n")
  })

  # Initialize the output list
  output <- list()

  # Add raw_LLM to output
  tryCatch({
    # Initialize two empty dataframes for var1 and var2
    flattened_df_var1 <- data.frame(var = character(),
                                    relationship = integer(),
                                    iteration = integer(),
                                    LLM_model = character(),
                                    prompt = character(),
                                    system_prompt = character(),
                                    content = character(),
                                    finish_reason = character(),
                                    prompt_tokens = numeric(),
                                    answer_tokens = numeric(),
                                    total_tokens = numeric(),
                                    error = character(),
                                    stringsAsFactors = FALSE)

    flattened_df_var2 <- data.frame(var = character(),
                                    relationship = integer(),
                                    iteration = integer(),
                                    LLM_model = character(),
                                    prompt = character(),
                                    system_prompt = character(),
                                    content = character(),
                                    finish_reason = character(),
                                    prompt_tokens = numeric(),
                                    answer_tokens = numeric(),
                                    total_tokens = numeric(),
                                    error = character(),
                                    stringsAsFactors = FALSE)

    # Flatten var1
    for (i in seq_along(raw_LLM_var1)) {
      for (j in seq_along(raw_LLM_var1[[i]])) {
        temp <- raw_LLM_var1[[i]][[j]]
        flattened_df_var1 <- rbind(flattened_df_var1,
                                   data.frame(var = "var1",
                                              relationship = i,
                                              iteration = j,
                                              LLM_model = temp$LLM_model,
                                              prompt = temp$prompt,
                                              system_prompt = temp$system_prompt,
                                              content = temp$content,
                                              finish_reason = temp$finish_reason,
                                              prompt_tokens = temp$prompt_tokens,
                                              answer_tokens = temp$answer_tokens,
                                              total_tokens = temp$total_tokens,
                                              error = ifelse(is.null(temp$error), NA, temp$error),
                                              stringsAsFactors = FALSE))
      }
    }

    # Flatten var2
    for (i in seq_along(raw_LLM_var2)) {
      for (j in seq_along(raw_LLM_var2[[i]])) {
        temp <- raw_LLM_var2[[i]][[j]]
        flattened_df_var2 <- rbind(flattened_df_var2,
                                   data.frame(var = "var2",
                                              relationship = i,
                                              iteration = j,
                                              LLM_model = temp$LLM_model,
                                              prompt = temp$prompt,
                                              system_prompt = temp$system_prompt,
                                              content = temp$content,
                                              finish_reason = temp$finish_reason,
                                              prompt_tokens = temp$prompt_tokens,
                                              answer_tokens = temp$answer_tokens,
                                              total_tokens = temp$total_tokens,
                                              error = ifelse(is.null(temp$error), NA, temp$error),
                                              stringsAsFactors = FALSE))
      }
    }

    # Combine the two dataframes
    raw_LLM_df <- rbind(flattened_df_var1, flattened_df_var2)
    output$raw_LLM <- raw_LLM_df

  }, error = function(e) {
    cat(paste0("Warning: Unable to return raw LLM output -> ", e$message, "."),
        "Only part of the output is returned.", sep = "\n")

  })


  # Adding relation_df to output
  output$direction_df <- direction_df

  print(paste0("Total of LLM prompts: ", n_causal_rela * 4))

  # give openai error if there is no output at all
  if (length(output) == 0) {
    for (i in row_index) {
      if (!is.null(raw_LLM_var1[[i]][[1]]$error$message)) {
        stop(raw_LLM_var1[[i]][[1]]$error$message)
      } else if (!is.null(raw_LLM_var1[[i]][[2]]$error$message)) {
        stop(raw_LLM_var1[[i]][[2]]$error$message)
      } else if (!is.null(raw_LLM_var2[[i]][[1]]$error$message)) {
        stop(raw_LLM_var2[[i]][[1]]$error$message)
      } else if (!is.null(raw_LLM_var2[[i]][[2]]$error$message)) {
        stop(raw_LLM_var2[[i]][[2]]$error$message)
      }
    }
  }

  return(output)
}
